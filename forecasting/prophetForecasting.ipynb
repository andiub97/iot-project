{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo4D4Yio9KGo"
      },
      "source": [
        "# Data Forecasting with prophet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PROPHET PREDICTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TESTO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljmAefVR9MU7"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install chart_studio\n",
        "!pip3 install pystan\n",
        "!pip3 install fbprophet\n",
        "!pip3 install glob2\n",
        "!pip3 install python-dateutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import DateOffset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime \n",
        "from datetime import timedelta\n",
        "import math\n",
        "import numpy as np\n",
        "import scipy.stats as st\n",
        "from fbprophet import Prophet\n",
        "from influxdb_client import InfluxDBClient\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from influxdb_client import InfluxDBClient, Point, WriteOptions\n",
        "from influxdb_client.client.write_api import SYNCHRONOUS\n",
        "from influxdb_client.client.write_api import WriteType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Influx Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "INFLUXDB_HOST = os.getenv(\"INFLUX_HOST\")\n",
        "INFLUXDB_PORT = os.getenv(\"INFLUX_HOST_PORT\")\n",
        "INFLUXDB_ORG = os.getenv(\"INFLUX_ORG\")\n",
        "INFLUXDB_TOKEN = os.getenv(\"INFLUX_TOKEN\")\n",
        "client = InfluxDBClient(url=\"http://\"+INFLUXDB_HOST+\":\"+INFLUXDB_PORT, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function convert Influx data in Panda Dataframes\n",
        "def convert_to_dataframe(result):\n",
        "    raw = []\n",
        "    for table in result:\n",
        "        for record in table.records:\n",
        "            raw.append((record.get_time(), record.get_value()))\n",
        "    return pd.DataFrame(raw, columns=['ds','y'], index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "buckets = ['temperature', 'humidity', 'gas']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#This function sends Forecasting Data to InfluxDB\n",
        "def send_predictions(prediction, bucket):\n",
        "\tlines = [str(prediction['yhat'][d]) for d in range(len(prediction))]\n",
        "\tif(bucket == \"gas\"):\n",
        "\t\tlines = ['val,prediction=yes,clientId=' + str(\"diubi-esp-32\")+\",lat=999,lng=999\"+ \" gasPred\" + '=' + str(prediction['yhat'][d])\n",
        "\t\t\t\t\t\t\t\t\t\t+ ' ' + str(int(time.mktime(prediction['ds'][d].timetuple()))) + \"000000000\" for d in range(len(prediction))]\n",
        "\telse:\n",
        "\t\tlines = ['val,prediction=yes,clientId=' + str(\"diubi-esp-32\")+\",lat=999,lng=999\"+ \" \" + bucket + '=' + str(prediction['yhat'][d])\n",
        "\t\t\t\t\t\t\t\t\t\t+ ' ' + str(int(time.mktime(prediction['ds'][d].timetuple()))) + \"000000000\" for d in range(len(prediction))]\n",
        "\twrite_client = client.write_api(write_options=WriteOptions(batch_size=1000, flush_interval=10_000,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tjitter_interval=2_000, retry_interval=5_000, write_type=WriteType.synchronous))\n",
        "\twrite_client.write(bucket, INFLUXDB_ORG, lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Prophet Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#With this function we obtain the forecasted data\n",
        "def bucket_forecast(bucket):\n",
        "    global mse_array\n",
        "    global forecasted_array\n",
        "    global expected_array\n",
        "    global forecasted\n",
        "    global expected\n",
        "    global forecast\n",
        "\n",
        "    mse_array = []\n",
        "    forecasted_array = []\n",
        "    expected_array = []\n",
        "    forecasted = []\n",
        "    expected = []\n",
        "    \n",
        "    print(bucket)\n",
        "    query = 'from(bucket: \"'+ bucket +'\")' \\\n",
        "                ' |> range(start: 2022-11-29T01:00:00.00Z, stop: 2022-12-01T13:00:00.00Z)'\\\n",
        "                ' |> filter(fn: (r) => r[\"_measurement\"] == \"val\")' \\\n",
        "                ' |> filter(fn: (r) => r[\"_field\"] == \"' + bucket +'\")' \\\n",
        "                ' |> filter(fn: (r) => r[\"clientId\"] == \"diubi-esp-32\")' \\\n",
        "                ' |> filter(fn: (r) => r[\"lat\"] == \"42.846290\")' \\\n",
        "                ' |> aggregateWindow(every: 3m , fn: mean, createEmpty: false)'\\\n",
        "                ' |> yield(name: \"mean\")'\\\n",
        "\n",
        "    result = client.query_api().query(org=INFLUXDB_ORG, query=query)\n",
        "    print(result)\n",
        "    \n",
        "    # Convert the results to dataframe\n",
        "    df = convert_to_dataframe(result)\n",
        "    \n",
        "    #adjust DateTime values\n",
        "    df['ds'] = df['ds'].dt.tz_localize(None)\n",
        "    \n",
        "    #train_size 80% - test_size 20%\n",
        "    nrows = (len(df.values))\n",
        "    splitPoint = int (nrows * 0.80)\n",
        "    train = df['y'] [:splitPoint].to_frame()\n",
        "    traindata = df['ds'] [:splitPoint]\n",
        "    train[\"ds\"] = traindata\n",
        "    test = df['y'][splitPoint:].to_frame()\n",
        "    testData = df['ds'][splitPoint:]\n",
        "    test[\"ds\"] = testData\n",
        "\n",
        "    #Prophet instance\n",
        "    m = Prophet(\n",
        "        yearly_seasonality=False,\n",
        "        weekly_seasonality=False,\n",
        "        daily_seasonality=True,\n",
        "        changepoint_range=1,\n",
        "        changepoint_prior_scale=0.01\n",
        "    ).fit(train)\n",
        "\n",
        "    #prediction period in minutes\n",
        "    test_interval = int((test.iloc[-1]['ds'].timestamp() - test.iloc[0]['ds'].timestamp()) / 60)\n",
        "    test_interval = test_interval + 5\n",
        "    \n",
        "    #make prediction\n",
        "    future = m.make_future_dataframe(periods=test_interval, \n",
        "             freq=DateOffset(minutes=1))\n",
        "    forecast = m.predict(future)\n",
        "    \n",
        "    forecast['ds'] = forecast.ds.dt.floor('min')\n",
        "\n",
        "    #send to INfluxDb forecasted data\n",
        "    send_predictions(forecast, bucket)\n",
        "\n",
        "    #preparing forecasted data for the evaluation phase\n",
        "    test['ds'] = test.ds.dt.floor('min')\n",
        "    metric = test.set_index('ds')[['y']].join(forecast.set_index('ds').yhat).reset_index()\n",
        "    metric = metric.dropna()\n",
        "    mse = mean_squared_error(metric['y'], metric['yhat'])\n",
        "    mse_array.append(mse)\n",
        "    expected_array.append(metric['y'].tolist())\n",
        "    forecasted_array.append(metric['yhat'].tolist())\n",
        "    forecasted = list(itertools.chain.from_iterable(forecasted_array))\n",
        "    expected = list(itertools.chain.from_iterable(expected_array))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prophet Model Results and Evalutaion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RMSE, Mean Value and Confidence Interval computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "APE = []\n",
        "i = 0\n",
        "for bucket in buckets:\n",
        "\tbucket_forecast(bucket)\n",
        "\tsend_predictions(forecast,bucket)\n",
        "\tprint(\"\\n\\nEvaluating \" + bucket)\n",
        "\tplt.plot(expected, label=\"Real Value\")\n",
        "\tplt.plot(forecasted, \"-r\", label=\"Forecasted Value\")\n",
        "\n",
        "\tplt.legend(loc=\"upper left\")\n",
        "\tplt.show()\n",
        "\n",
        "\t#Mean Square Error & Root Square Error considered more accurate \n",
        "\tmse = mean_squared_error(expected, forecasted)\n",
        "\tprint('mse')\n",
        "\tprint(mse) #mah\n",
        "\trmse = math.sqrt(mean_squared_error(expected, forecasted))\n",
        "\tprint('Test RMSE: %.3f'%rmse)\n",
        "\n",
        "\t\n",
        "\t# MAE\n",
        "\t# The mean absolute error, or MAE, \n",
        "\t# is calculated as the average of the forecast error values, \n",
        "\t# where all of the forecast error values are forced to be positive.\n",
        "\t# These error values are in the original units of the predicted values. \n",
        "\t# A mean absolute error of zero indicates no error.\n",
        "\n",
        "\t# Calculate the MAE \n",
        "\tmae = mean_absolute_error(expected, forecasted)\n",
        "\tprint('MAE: %f' % mae)\n",
        "\n",
        "\n",
        "\t# A confidence interval is an estimation technique used in statistical inference to constrain a pair or pairs of values, \n",
        "\t# within which the desired point estimate will be found (with a certain probability).\n",
        "\n",
        "\t# A confidence interval will allow us to calculate two values around a sample mean (one upper and one lower). \n",
        "\t# These values will bound an interval within which, with some probability, the population parameter will be found.\n",
        "\n",
        "\n",
        "\tmean = sum(forecasted) / len(forecasted) #mean\n",
        "\tprint(\"Mean: \",mean)\n",
        "\n",
        "\n",
        "\tstd = np.std(forecasted)  # standard deviation\n",
        "\tprint(\"Standard Deviation: \",std)\n",
        "\n",
        "\t# create 95% confidence interval\n",
        "\tres = st.t.interval(confidence=0.95, df=len(forecasted)-1,\n",
        "\t\t\t\tloc=np.mean(forecasted),\n",
        "\t\t\t\tscale=st.sem(forecasted))\n",
        "\n",
        "\tprint(\"Confidence intervals: \",res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "forecasting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
